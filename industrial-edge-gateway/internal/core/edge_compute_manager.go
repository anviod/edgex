package core

import (
	"bytes"
	"encoding/json"
	"fmt"
	"industrial-edge-gateway/internal/model"
	"industrial-edge-gateway/internal/storage"
	"log"
	"math"
	"net/http"
	"os"
	"sort"
	"strconv"
	"strings"
	"sync"
	"time"

	"github.com/expr-lang/expr"
)

type ruleTask struct {
	rule model.EdgeRule
	val  model.Value
}

type EdgeComputeManager struct {
	rules      map[string]model.EdgeRule
	pipeline   *DataPipeline
	nbm        *NorthboundManager
	cm         *ChannelManager
	store      *storage.Storage
	mu         sync.RWMutex
	saveFunc   func([]model.EdgeRule) error
	ruleStates map[string]*model.RuleRuntimeState
	windows    map[string][]model.Value
	stateMu    sync.RWMutex
	valueCache map[string]model.Value
	cacheMu    sync.RWMutex

	// Shared Source Index
	ruleIndex map[string][]string // Key: "ChannelID/DeviceID/PointID", Value: []RuleID
	indexMu   sync.RWMutex

	// Worker Pool
	workerPool  chan *ruleTask
	workerCount int
	wg          sync.WaitGroup

	// Metrics
	statsMu        sync.RWMutex
	rulesTriggered int64
	rulesExecuted  int64
	rulesDropped   int64

	stopOnce sync.Once

	// Minute-level bblot cache
	bblotMu     sync.Mutex
	minuteCache map[string]*model.RuleMinuteSnapshot

	// Test Hook
	actionHook func(ruleID string, action model.RuleAction, val model.Value, env map[string]any, err error)

	// Dependency Injection for Testing
	writer DeviceWriter
}

type DeviceWriter interface {
	WritePoint(channelID, deviceID, pointID string, value any) error
}

type EdgeComputeMetrics struct {
	WorkerPoolSize    int   `json:"worker_pool_size"`
	WorkerPoolUsage   int   `json:"worker_pool_usage"`
	RuleCount         int   `json:"rule_count"`
	SharedSourceCount int   `json:"shared_source_count"`
	CacheSize         int   `json:"cache_size"`
	RulesTriggered    int64 `json:"rules_triggered"`
	RulesExecuted     int64 `json:"rules_executed"`
	RulesDropped      int64 `json:"rules_dropped"`
}

func NewEdgeComputeManager(pipeline *DataPipeline, store *storage.Storage, saveFunc func([]model.EdgeRule) error) *EdgeComputeManager {
	return &EdgeComputeManager{
		rules:       make(map[string]model.EdgeRule),
		pipeline:    pipeline,
		store:       store,
		saveFunc:    saveFunc,
		ruleStates:  make(map[string]*model.RuleRuntimeState),
		windows:     make(map[string][]model.Value),
		valueCache:  make(map[string]model.Value),
		minuteCache: make(map[string]*model.RuleMinuteSnapshot),
		ruleIndex:   make(map[string][]string),
		workerPool:  make(chan *ruleTask, 1000), // Buffer size 1000
		workerCount: 10,                         // Default 10 workers
	}
}

type SharedSourceInfo struct {
	SourceID        string   `json:"source_id"`
	Subscribers     []string `json:"subscribers"`
	SubscriberCount int      `json:"subscriber_count"`
}

func (em *EdgeComputeManager) GetSharedSources() []SharedSourceInfo {
	em.indexMu.RLock()
	defer em.indexMu.RUnlock()

	var result []SharedSourceInfo
	for source, rules := range em.ruleIndex {
		info := SharedSourceInfo{
			SourceID:        source,
			Subscribers:     make([]string, len(rules)),
			SubscriberCount: len(rules),
		}
		copy(info.Subscribers, rules)
		result = append(result, info)
	}
	return result
}

func (em *EdgeComputeManager) GetMetrics() EdgeComputeMetrics {
	em.statsMu.RLock()
	defer em.statsMu.RUnlock()
	em.mu.RLock()
	ruleCount := len(em.rules)
	em.mu.RUnlock()
	em.indexMu.RLock()
	sourceCount := len(em.ruleIndex)
	em.indexMu.RUnlock()
	em.cacheMu.RLock()
	cacheSize := len(em.valueCache)
	em.cacheMu.RUnlock()

	return EdgeComputeMetrics{
		WorkerPoolSize:    cap(em.workerPool),
		WorkerPoolUsage:   len(em.workerPool),
		RuleCount:         ruleCount,
		SharedSourceCount: sourceCount,
		CacheSize:         cacheSize,
		RulesTriggered:    em.rulesTriggered,
		RulesExecuted:     em.rulesExecuted,
		RulesDropped:      em.rulesDropped,
	}
}

func (em *EdgeComputeManager) SetNorthboundManager(nbm *NorthboundManager) {
	em.nbm = nbm
}

func (em *EdgeComputeManager) SetChannelManager(cm *ChannelManager) {
	em.cm = cm
	if em.writer == nil {
		em.writer = cm
	}
}

func (em *EdgeComputeManager) SetDeviceWriter(w DeviceWriter) {
	em.writer = w
}

func (em *EdgeComputeManager) SetStorage(s *storage.Storage) {
	em.store = s
}

func (em *EdgeComputeManager) SetActionHook(hook func(ruleID string, action model.RuleAction, val model.Value, env map[string]any, err error)) {
	em.actionHook = hook
}

func (em *EdgeComputeManager) LoadRules(rules []model.EdgeRule) {
	em.mu.Lock()
	defer em.mu.Unlock()
	for _, r := range rules {
		em.rules[r.ID] = r
	}
	em.rebuildIndex()
	log.Printf("Loaded %d edge computing rules", len(rules))
}

func (em *EdgeComputeManager) Start() {
	// Restore state from DB
	em.restoreState()

	// Start Workers
	for i := 0; i < em.workerCount; i++ {
		em.wg.Add(1)
		go em.workerLoop(i)
	}

	// Register handler to data pipeline
	em.pipeline.AddHandler(em.handleValue)

	// Start retry loop
	go em.retryLoop()

	log.Println("Edge Compute Manager started with", em.workerCount, "workers")
}

func (em *EdgeComputeManager) Stop() {
	em.stopOnce.Do(func() {
		close(em.workerPool)
		em.wg.Wait()
	})
}

func (em *EdgeComputeManager) workerLoop(id int) {
	defer em.wg.Done()
	for task := range em.workerPool {
		em.executeRule(task.rule, task.val)
		em.statsMu.Lock()
		em.rulesExecuted++
		em.statsMu.Unlock()
	}
}

func (em *EdgeComputeManager) rebuildIndex() {
	em.indexMu.Lock()
	defer em.indexMu.Unlock()

	em.ruleIndex = make(map[string][]string)
	for _, rule := range em.rules {
		em.indexRule(rule)
	}
}

func (em *EdgeComputeManager) indexRule(rule model.EdgeRule) {
	// Helper to add key
	addKey := func(cid, did, pid string) {
		key := fmt.Sprintf("%s/%s/%s", cid, did, pid)
		// Check duplicates
		for _, id := range em.ruleIndex[key] {
			if id == rule.ID {
				return
			}
		}
		em.ruleIndex[key] = append(em.ruleIndex[key], rule.ID)
	}

	if len(rule.Sources) > 0 {
		for _, src := range rule.Sources {
			addKey(src.ChannelID, src.DeviceID, src.PointID)
		}
	} else {
		// Legacy
		addKey(rule.Source.ChannelID, rule.Source.DeviceID, rule.Source.PointID)
	}
}

func (em *EdgeComputeManager) removeFromIndex(ruleID string) {
	em.indexMu.Lock()
	defer em.indexMu.Unlock()

	for key, ids := range em.ruleIndex {
		newIDs := make([]string, 0)
		for _, id := range ids {
			if id != ruleID {
				newIDs = append(newIDs, id)
			}
		}
		if len(newIDs) == 0 {
			delete(em.ruleIndex, key)
		} else {
			em.ruleIndex[key] = newIDs
		}
	}
}

func (em *EdgeComputeManager) handleValue(val model.Value) {
	// Update Cache (Thread Safe)
	cacheKey := fmt.Sprintf("%s/%s/%s", val.ChannelID, val.DeviceID, val.PointID)
	em.cacheMu.Lock()
	em.valueCache[cacheKey] = val
	em.cacheMu.Unlock()

	// Find Matched Rules via Index (O(1) lookup)
	em.indexMu.RLock()
	ruleIDs, exists := em.ruleIndex[cacheKey]
	em.indexMu.RUnlock()

	if !exists || len(ruleIDs) == 0 {
		return
	}

	em.mu.RLock()
	var matchedRules []model.EdgeRule
	for _, id := range ruleIDs {
		if rule, ok := em.rules[id]; ok {
			if rule.Enable {
				matchedRules = append(matchedRules, rule)
			}
		}
	}
	em.mu.RUnlock()

	// Sort by Priority (High to Low)
	if len(matchedRules) > 1 {
		sort.Slice(matchedRules, func(i, j int) bool {
			return matchedRules[i].Priority > matchedRules[j].Priority
		})
	}

	// Dispatch to Worker Pool
	for _, rule := range matchedRules {
		em.statsMu.Lock()
		em.rulesTriggered++
		em.statsMu.Unlock()

		select {
		case em.workerPool <- &ruleTask{rule: rule, val: val}:
			// Queued successfully
		default:
			em.statsMu.Lock()
			em.rulesDropped++
			em.statsMu.Unlock()
			log.Printf("[EdgeCompute] Worker pool full, dropping rule execution for rule %s", rule.ID)
		}
	}
}

func matchRule(rule model.EdgeRule, val model.Value) bool {
	// New Multi-source match
	if len(rule.Sources) > 0 {
		for _, src := range rule.Sources {
			if matchSource(src, val) {
				return true
			}
		}
		return false
	}
	// Legacy match
	return matchSource(rule.Source, val)
}

func matchSource(src model.RuleSource, val model.Value) bool {
	// If ID is empty, it matches all (wildcard) - but usually we want specific match
	// For now, strict match if ID is provided
	if src.ChannelID != "" && src.ChannelID != val.ChannelID {
		return false
	}
	if src.DeviceID != "" && src.DeviceID != val.DeviceID {
		return false
	}
	if src.PointID != "" && src.PointID != val.PointID {
		return false
	}
	return true
}

func (em *EdgeComputeManager) executeRule(rule model.EdgeRule, val model.Value) {
	em.stateMu.Lock()
	state, exists := em.ruleStates[rule.ID]
	if !exists {
		state = &model.RuleRuntimeState{
			RuleID:        rule.ID,
			RuleName:      rule.Name,
			Enable:        rule.Enable,
			CurrentStatus: "NORMAL",
		}
		em.ruleStates[rule.ID] = state
	}
	em.stateMu.Unlock()

	// Prepare Env for Expression
	env := make(map[string]any)
	// Try to convert trigger value to float for numeric comparisons
	triggerVal := val.Value
	if fVal, ok := toFloat(triggerVal); ok {
		triggerVal = fVal
	}
	env["value"] = triggerVal // Current triggering value

	// Populate env with aliases from cache
	if len(rule.Sources) > 0 {
		em.cacheMu.RLock()
		for _, src := range rule.Sources {
			if src.Alias == "" && src.PointID == "" {
				continue
			}

			var srcVal any
			found := false

			// Check if the triggering value belongs to this source
			// If so, use the triggering value as it is the most up-to-date
			if matchSource(src, val) {
				srcVal = val.Value
				found = true
			} else {
				key := fmt.Sprintf("%s/%s/%s", src.ChannelID, src.DeviceID, src.PointID)
				if v, ok := em.valueCache[key]; ok {
					srcVal = v.Value
					found = true
				}
			}

			if found {
				// Try to convert to float for better expression compatibility
				if fVal, ok := toFloat(srcVal); ok {
					srcVal = fVal
				}

				if src.Alias != "" {
					env[src.Alias] = srcVal
				}
				if src.PointID != "" {
					env[src.PointID] = srcVal
				}
			} else {
				// Missing value - use NaN to ensure comparisons fail safely (false) instead of crashing
				if src.Alias != "" {
					env[src.Alias] = math.NaN()
				}
				if src.PointID != "" {
					env[src.PointID] = math.NaN()
				}
			}
		}
		em.cacheMu.RUnlock()
	}

	// Logic refactored: Logic is now fully determined by the Condition expression using aliases.
	// AND/OR branching is removed.

	var triggered bool
	var err error
	var outputVal model.Value = val

	switch rule.Type {
	case "threshold":
		triggered, err = evaluateThreshold(rule.Condition, env)
	case "calculation":
		// Calculation rules always "trigger" if calculation succeeds,
		// and they output a new value.
		var res any
		res, err = evaluateCalculation(rule.Expression, env)
		if err == nil {
			outputVal.Value = res
			triggered = true
		}
	case "window":
		triggered, outputVal, err = em.evaluateWindow(rule, val, env)
	case "state":
		triggered, err = em.evaluateState(rule, val, state, env)
	default:
		// Default to threshold if condition exists, otherwise ignore
		if rule.Condition != "" {
			triggered, err = evaluateThreshold(rule.Condition, env)
		}
	}

	em.stateMu.Lock()
	defer em.stateMu.Unlock()

	// Persist state changes
	defer func() { go em.saveRuleState(rule.ID) }()

	if err != nil {
		state.ErrorMessage = err.Error()
		log.Printf("Rule %s evaluation error: %v", rule.Name, err)
		return
	}

	if triggered {
		prevStatus := state.CurrentStatus

		state.LastTrigger = time.Now()
		state.TriggerCount++
		state.CurrentStatus = "ALARM"
		state.LastValue = outputVal.Value
		state.ErrorMessage = ""

		// Record execution result to bblot
		em.recordMinuteSnapshot(state)

		// Check TriggerMode
		shouldExecute := true
		if rule.TriggerMode == "on_change" {
			// Only execute if previous status was NOT ALARM
			if prevStatus == "ALARM" {
				shouldExecute = false
			}
		}

		if shouldExecute {
			go em.executeActions(rule.ID, rule.Actions, outputVal, env)
		}
	} else {
		// For State rules, we might be in "Pending" state (waiting for duration),
		// but if triggered is false, it means we are either NORMAL or PENDING.
		// If we are resetting, we are NORMAL.
		if rule.Type == "state" {
			// Check internal state to decide if NORMAL or WARNING
			if !state.ConditionStart.IsZero() {
				state.CurrentStatus = "WARNING"
			} else {
				state.CurrentStatus = "NORMAL"
			}
		} else {
			state.CurrentStatus = "NORMAL"
		}
		// Record status change/normal state to bblot
		em.recordMinuteSnapshot(state)
	}
}

func (em *EdgeComputeManager) recordMinuteSnapshot(state *model.RuleRuntimeState) {
	if em.store == nil {
		return
	}

	minuteKey := time.Now().Format("2006-01-02 15:04")
	cacheKey := fmt.Sprintf("%s_%s", state.RuleID, minuteKey)

	em.bblotMu.Lock()
	snap, exists := em.minuteCache[cacheKey]
	if !exists {
		snap = &model.RuleMinuteSnapshot{
			RuleID:    state.RuleID,
			RuleName:  state.RuleName,
			Minute:    minuteKey,
			Status:    state.CurrentStatus,
			UpdatedAt: time.Now(),
		}
		em.minuteCache[cacheKey] = snap
	}

	// Update snapshot
	snap.Status = state.CurrentStatus
	snap.TriggerCount = state.TriggerCount
	snap.LastValue = state.LastValue
	snap.LastTrigger = state.LastTrigger
	snap.ErrorMessage = state.ErrorMessage
	snap.UpdatedAt = time.Now()

	// Create a copy for async saving to avoid race conditions
	snapCopy := *snap
	em.bblotMu.Unlock()

	// Persist asynchronously
	go func(snapshot model.RuleMinuteSnapshot) {
		// Use minuteKey as part of the key to ensure one record per minute per rule
		key := fmt.Sprintf("%s_%s", snapshot.RuleID, snapshot.Minute)
		if err := em.store.SaveData("bblot", key, snapshot); err != nil {
			log.Printf("Failed to save bblot snapshot: %v", err)
		}
	}(snapCopy)
}

// QueryLogs retrieves logs based on time range and optional rule ID
func (em *EdgeComputeManager) QueryLogs(start, end time.Time, ruleID string) ([]model.RuleMinuteSnapshot, error) {
	if em.store == nil {
		return nil, fmt.Errorf("storage not initialized")
	}

	var logs []model.RuleMinuteSnapshot
	bucket := "bblot"

	startStr := start.Format("2006-01-02 15:04")
	endStr := end.Format("2006-01-02 15:04")

	if ruleID != "" {
		// Optimized range scan
		minKey := fmt.Sprintf("%s_%s", ruleID, startStr)
		maxKey := fmt.Sprintf("%s_%s", ruleID, endStr)

		err := em.store.LoadRange(bucket, minKey, maxKey, func(k, v []byte) error {
			var snap model.RuleMinuteSnapshot
			if err := json.Unmarshal(v, &snap); err != nil {
				return nil // Skip invalid data
			}
			logs = append(logs, snap)
			return nil
		})
		return logs, err
	}

	// Full scan and filter
	err := em.store.LoadAll(bucket, func(k, v []byte) error {
		var snap model.RuleMinuteSnapshot
		if err := json.Unmarshal(v, &snap); err != nil {
			return nil
		}
		// Filter by time range
		if snap.Minute >= startStr && snap.Minute <= endStr {
			logs = append(logs, snap)
		}
		return nil
	})

	return logs, err
}

func (em *EdgeComputeManager) evaluateWindow(rule model.EdgeRule, val model.Value, baseEnv map[string]any) (bool, model.Value, error) {
	if rule.Window == nil {
		return false, val, fmt.Errorf("missing window config")
	}

	em.stateMu.Lock()
	history := em.windows[rule.ID]
	history = append(history, val)

	// Window Logic (Simplified: Count based or Time based)
	// For now, assume Size is duration "10s" or count "10"
	// Parse Size
	sizeDur, errDur := time.ParseDuration(rule.Window.Size)
	isTimeWindow := errDur == nil

	var filtered []model.Value
	if isTimeWindow {
		cutoff := val.TS.Add(-sizeDur)
		for _, v := range history {
			if v.TS.After(cutoff) || v.TS.Equal(cutoff) {
				filtered = append(filtered, v)
			}
		}
	} else {
		// Count window
		count := 10 // Default
		fmt.Sscanf(rule.Window.Size, "%d", &count)
		if len(history) > count {
			filtered = history[len(history)-count:]
		} else {
			filtered = history
		}
	}

	em.windows[rule.ID] = filtered
	em.stateMu.Unlock()

	// Persist window data asynchronously
	go em.saveWindowData(rule.ID)

	// Aggregation
	var result float64
	var count int
	var minVal, maxVal float64
	var firstVal, lastVal float64
	var firstTime, lastTime time.Time

	for i, v := range filtered {
		f, ok := toFloat(v.Value)
		if ok {
			if i == 0 {
				minVal = f
				maxVal = f
				firstVal = f
				firstTime = v.TS
			}
			lastVal = f
			lastTime = v.TS

			switch rule.Window.AggrFunc {
			case "sum", "avg":
				result += f
			case "max":
				if f > maxVal {
					maxVal = f
				}
			case "min":
				if f < minVal {
					minVal = f
				}
			}
			count++
		}
	}

	switch rule.Window.AggrFunc {
	case "max":
		result = maxVal
	case "min":
		result = minVal
	case "avg":
		if count > 0 {
			result = result / float64(count)
		}
	case "count":
		result = float64(count)
	case "rate":
		// (Last - First) / Duration (in seconds)
		if count > 1 {
			duration := lastTime.Sub(firstTime).Seconds()
			if duration > 0 {
				result = (lastVal - firstVal) / duration
			} else {
				result = 0
			}
		} else {
			result = 0
		}
	}

	// Evaluate Condition against Result
	env := make(map[string]any)
	for k, v := range baseEnv {
		env[k] = v
	}
	env["value"] = result

	triggered, err := evaluateThreshold(rule.Condition, env)

	outputVal := val
	outputVal.Value = result

	return triggered, outputVal, err
}

func (em *EdgeComputeManager) evaluateState(rule model.EdgeRule, val model.Value, state *model.RuleRuntimeState, baseEnv map[string]any) (bool, error) {
	// First check basic condition
	env := make(map[string]any)
	for k, v := range baseEnv {
		env[k] = v
	}
	env["value"] = val.Value

	conditionMet, err := evaluateThreshold(rule.Condition, env)
	if err != nil {
		return false, err
	}

	em.stateMu.Lock()
	defer func() {
		em.stateMu.Unlock()
		go em.saveRuleState(rule.ID)
	}()

	if !conditionMet {
		// Condition not met, reset state
		state.ConditionStart = time.Time{}
		state.ConditionCount = 0
		return false, nil
	}

	// Condition is met
	if state.ConditionStart.IsZero() {
		state.ConditionStart = time.Now()
	}
	state.ConditionCount++

	// Check constraints
	if rule.State != nil {
		// Check Duration
		if rule.State.Duration != "" {
			dur, err := time.ParseDuration(rule.State.Duration)
			if err == nil {
				if time.Since(state.ConditionStart) < dur {
					return false, nil // Wait for duration
				}
			}
		}

		// Check Count
		if rule.State.Count > 0 {
			if state.ConditionCount < rule.State.Count {
				return false, nil // Wait for count
			}
		}
	}

	// All constraints met
	return true, nil
}

func toFloat(v any) (float64, bool) {
	switch i := v.(type) {
	case float64:
		return i, true
	case float32:
		return float64(i), true
	case int:
		return float64(i), true
	case int64:
		return float64(i), true
	case int32:
		return float64(i), true
	case uint:
		return float64(i), true
	case uint64:
		return float64(i), true
	case uint32:
		return float64(i), true
	case string:
		f, err := strconv.ParseFloat(i, 64)
		return f, err == nil
	case bool:
		if i {
			return 1, true
		}
		return 0, true
	default:
		return 0, false
	}
}

func (em *EdgeComputeManager) GetRuleStates() map[string]*model.RuleRuntimeState {
	em.stateMu.RLock()
	defer em.stateMu.RUnlock()

	copy := make(map[string]*model.RuleRuntimeState)
	for k, v := range em.ruleStates {
		// Deep copy or shallow copy? Ptr is fine if we don't modify it outside
		c := *v
		copy[k] = &c
	}
	return copy
}

func (em *EdgeComputeManager) GetWindowData(ruleID string) []model.Value {
	em.stateMu.RLock()
	defer em.stateMu.RUnlock()

	if data, ok := em.windows[ruleID]; ok {
		// Return a copy
		res := make([]model.Value, len(data))
		copy(res, data)
		return res
	}
	return []model.Value{}
}

func evaluateThreshold(condition string, env map[string]any) (bool, error) {
	env = prepareExprEnv(env)
	program, err := expr.Compile(condition, expr.Env(env))
	if err != nil {
		return false, err
	}
	output, err := expr.Run(program, env)
	if err != nil {
		return false, err
	}
	if res, ok := output.(bool); ok {
		return res, nil
	}
	return false, fmt.Errorf("condition must return boolean")
}

func evaluateCalculation(expression string, env map[string]any) (any, error) {
	env = prepareExprEnv(env)
	program, err := expr.Compile(expression, expr.Env(env))
	if err != nil {
		return nil, err
	}
	output, err := expr.Run(program, env)
	if err != nil {
		return nil, err
	}
	return output, nil
}

func prepareExprEnv(env map[string]any) map[string]any {
	if env == nil {
		env = make(map[string]any)
	}
	// Check if already populated to avoid re-adding
	if _, ok := env["bitand"]; ok {
		return env
	}

	env["bitand"] = func(a, b any) (int64, error) { return bitwiseOp(a, b, func(x, y int64) int64 { return x & y }) }
	env["bitor"] = func(a, b any) (int64, error) { return bitwiseOp(a, b, func(x, y int64) int64 { return x | y }) }
	env["bitxor"] = func(a, b any) (int64, error) { return bitwiseOp(a, b, func(x, y int64) int64 { return x ^ y }) }
	env["bitnot"] = func(a any) (int64, error) { return bitwiseUnary(a, func(x int64) int64 { return ^x }) }
	env["bitshl"] = func(a, b any) (int64, error) { return bitwiseOp(a, b, func(x, y int64) int64 { return x << y }) }
	env["bitshr"] = func(a, b any) (int64, error) { return bitwiseOp(a, b, func(x, y int64) int64 { return x >> y }) }
	
	return env
}

func bitwiseOp(a, b any, op func(int64, int64) int64) (int64, error) {
	ia, err := toInt64(a)
	if err != nil {
		return 0, err
	}
	ib, err := toInt64(b)
	if err != nil {
		return 0, err
	}
	return op(ia, ib), nil
}

func bitwiseUnary(a any, op func(int64) int64) (int64, error) {
	ia, err := toInt64(a)
	if err != nil {
		return 0, err
	}
	return op(ia), nil
}

func toInt64(v any) (int64, error) {
	switch val := v.(type) {
	case int:
		return int64(val), nil
	case int8:
		return int64(val), nil
	case int16:
		return int64(val), nil
	case int32:
		return int64(val), nil
	case int64:
		return val, nil
	case uint:
		return int64(val), nil
	case uint8:
		return int64(val), nil
	case uint16:
		return int64(val), nil
	case uint32:
		return int64(val), nil
	case uint64:
		return int64(val), nil
	case float32:
		return int64(val), nil
	case float64:
		return int64(val), nil
	case string:
		f, err := strconv.ParseFloat(val, 64)
		if err == nil {
			return int64(f), nil
		}
		// Try parsing as int directly if float parse fails (though float parse handles ints)
		i, err := strconv.ParseInt(val, 0, 64)
		if err == nil {
			return i, nil
		}
		return 0, fmt.Errorf("cannot convert string '%s' to int64", val)
	default:
		return 0, fmt.Errorf("cannot convert %T to int64", v)
	}
}

func (em *EdgeComputeManager) executeActions(ruleID string, actions []model.RuleAction, val model.Value, env map[string]any) {
	for _, action := range actions {
		go func(act model.RuleAction) {
			err := em.executeSingleAction(ruleID, act, val, env)
			if em.actionHook != nil {
				em.actionHook(ruleID, act, val, env, err)
			}
			if err != nil {
				log.Printf("[EdgeAction] Action failed: %v", err)
				em.saveFailedAction(ruleID, act, val, env, err.Error())
			}
		}(action)
	}
}

func (em *EdgeComputeManager) resolveValueTemplate(val any, env map[string]any) any {
	strVal, ok := val.(string)
	if !ok {
		return val
	}
	// Check if it looks like a template
	if !strings.Contains(strVal, "${") {
		return val
	}

	// Resolve template
	resolved := os.Expand(strVal, func(k string) string {
		if v, ok := env[k]; ok {
			return fmt.Sprintf("%v", v)
		}
		return ""
	})

	return resolved
}

func (em *EdgeComputeManager) executeSingleAction(ruleID string, action model.RuleAction, val model.Value, env map[string]any) error {
	switch action.Type {
	case "database":
		if em.store == nil {
			return fmt.Errorf("storage not available")
		}
		bucket, _ := action.Config["bucket"].(string)
		if bucket == "" {
			bucket = "rule_events"
		}
		// Use timestamp as key if not provided
		key := fmt.Sprintf("%s_%d", ruleID, time.Now().UnixNano())

		data := map[string]interface{}{
			"rule_id": ruleID,
			"value":   val,
			"time":    time.Now(),
		}

		return em.store.SaveData(bucket, key, data)
	case "log":
		log.Printf("[EdgeAction] LOG: Rule triggered for %s, Value: %v", val.PointID, val.Value)
		return nil
	case "mqtt":
		if em.nbm == nil {
			return fmt.Errorf("NorthboundManager not available")
		}
		topic, _ := action.Config["topic"].(string)
		if topic == "" {
			return nil // Skip if no topic
		}
		clientID, _ := action.Config["client_id"].(string)
		strategy, _ := action.Config["send_strategy"].(string)

		var payload []byte
		var err error

		if strategy == "batch" {
			// Send all source values from env
			// Filter out "value" which is a duplicate of one source
			batchData := make(map[string]any)
			for k, v := range env {
				if k != "value" {
					batchData[k] = v
				}
			}
			// If env only had "value" (no aliases), use val
			if len(batchData) == 0 {
				payload, err = json.Marshal(val)
			} else {
				payload, err = json.Marshal(batchData)
			}
		} else {
			// Default: Send triggering value
			payload, err = json.Marshal(val)
		}
		if err != nil {
			return err
		}

		// If message is provided in config, use it (Template overrides payload)
		if msg, ok := action.Config["message"].(string); ok && msg != "" {
			// Resolve templates
			resolvedMsg := os.Expand(msg, func(k string) string {
				if v, ok := env[k]; ok {
					return fmt.Sprintf("%v", v)
				}
				return ""
			})
			payload = []byte(resolvedMsg)
		}

		return em.nbm.PublishMQTT(clientID, topic, payload)
	case "device_control":
		if em.writer == nil {
			return fmt.Errorf("DeviceWriter not available")
		}

		// Check for multiple targets
		if targets, ok := action.Config["targets"].([]interface{}); ok && len(targets) > 0 {
			var errs []error
			for _, t := range targets {
				targetMap, ok := t.(map[string]interface{})
				if !ok {
					continue
				}
				cid, _ := targetMap["channel_id"].(string)
				did, _ := targetMap["device_id"].(string)
				pid, _ := targetMap["point_id"].(string)
				valToWrite := targetMap["value"]
				expression, _ := targetMap["expression"].(string)

				if cid != "" && did != "" && pid != "" {
					// 1. Resolve expression if present
					if expression != "" {
						// Prepare Env for Expression
						calcEnv := make(map[string]any)
						for k, v := range env {
							calcEnv[k] = v
						}
						// Ensure 'v' is available in env (alias for value)
						// If value is numeric, use float64, otherwise original
						if fVal, ok := toFloat(val.Value); ok {
							calcEnv["v"] = fVal
						} else {
							calcEnv["v"] = val.Value
						}

						res, err := evaluateCalculation(expression, calcEnv)
						if err == nil {
							valToWrite = res
						} else {
							log.Printf("[EdgeAction] Failed to evaluate expression '%s': %v", expression, err)
							// Fallback to value or keep valToWrite as is?
							// If expression fails, maybe we should NOT write?
							// For now, let's log and fallback to static value
						}
					}

					// 2. Resolve value template if string (and no expression success or expression result is string)
					if valToWrite != nil {
						valToWrite = em.resolveValueTemplate(valToWrite, env)
					} else {
						valToWrite = val.Value
					}

					if err := em.writer.WritePoint(cid, did, pid, valToWrite); err != nil {
						errs = append(errs, fmt.Errorf("failed to write %s/%s/%s: %v", cid, did, pid, err))
					}
				}
			}
			if len(errs) > 0 {
				return fmt.Errorf("batch control errors: %v", errs)
			}
			return nil
		}

		// Single target (Legacy)
		channelID, _ := action.Config["channel_id"].(string)
		deviceID, _ := action.Config["device_id"].(string)
		pointID, _ := action.Config["point_id"].(string)
		valToWrite := action.Config["value"]

		if channelID == "" || deviceID == "" || pointID == "" {
			return fmt.Errorf("missing channel_id, device_id or point_id")
		}

		// Resolve value if it is a string template or nil
		if valToWrite == nil {
			valToWrite = val.Value
		} else {
			// Try to resolve template if valToWrite is string
			valToWrite = em.resolveValueTemplate(valToWrite, env)
		}

		return em.writer.WritePoint(channelID, deviceID, pointID, valToWrite)
	case "http":
		url, _ := action.Config["url"].(string)
		if url == "" {
			return nil
		}
		method, _ := action.Config["method"].(string)
		if method == "" {
			method = "POST"
		}
		strategy, _ := action.Config["send_strategy"].(string)

		var payload []byte
		var err error

		if strategy == "batch" {
			batchData := make(map[string]any)
			for k, v := range env {
				if k != "value" {
					batchData[k] = v
				}
			}
			if len(batchData) == 0 {
				payload, err = json.Marshal(val)
			} else {
				payload, err = json.Marshal(batchData)
			}
		} else {
			payload, err = json.Marshal(val)
		}
		if err != nil {
			return err
		}

		if msg, ok := action.Config["body"].(string); ok && msg != "" {
			// Resolve templates
			resolvedMsg := os.Expand(msg, func(k string) string {
				if v, ok := env[k]; ok {
					return fmt.Sprintf("%v", v)
				}
				return ""
			})
			payload = []byte(resolvedMsg)
		}

		req, err := http.NewRequest(method, url, bytes.NewBuffer(payload))
		if err != nil {
			return err
		}
		req.Header.Set("Content-Type", "application/json")
		client := &http.Client{}
		resp, err := client.Do(req)
		if err != nil {
			return err
		}
		defer resp.Body.Close()
		return nil
	}
	return nil
}

func (em *EdgeComputeManager) saveFailedAction(ruleID string, action model.RuleAction, val model.Value, env map[string]any, errStr string) {
	if em.store == nil {
		return
	}
	// Only retry idempotent actions or safe ones
	// For now support mqtt and device_control
	if action.Type != "mqtt" && action.Type != "device_control" {
		return
	}

	fa := model.FailedAction{
		ID:         fmt.Sprintf("%d", time.Now().UnixNano()),
		RuleID:     ruleID,
		Action:     action,
		Value:      val,
		Timestamp:  time.Now(),
		RetryCount: 0,
		LastError:  errStr,
		Env:        env,
	}
	if err := em.store.SaveData("DataCache", fa.ID, fa); err != nil {
		log.Printf("Failed to save failed action: %v", err)
	}
}

func (em *EdgeComputeManager) retryLoop() {
	ticker := time.NewTicker(30 * time.Second)
	for range ticker.C {
		em.processFailedActions()
	}
}

func (em *EdgeComputeManager) processFailedActions() {
	if em.store == nil {
		return
	}
	em.store.LoadAll("DataCache", func(k, v []byte) error {
		var fa model.FailedAction
		if err := json.Unmarshal(v, &fa); err != nil {
			return nil
		}

		// Retry logic
		err := em.executeSingleAction(fa.RuleID, fa.Action, fa.Value, fa.Env)
		if err == nil {
			// Success, remove
			em.store.DeleteData("DataCache", fa.ID)
			log.Printf("Retry success for action %s", fa.ID)
		} else {
			// Fail, update count
			fa.RetryCount++
			fa.LastError = err.Error()
			if fa.RetryCount > 10 { // Max retries
				em.store.DeleteData("DataCache", fa.ID)
				log.Printf("Max retries reached for action %s, dropping", fa.ID)
			} else {
				em.store.SaveData("DataCache", fa.ID, fa)
			}
		}
		return nil
	})
}

func (em *EdgeComputeManager) GetFailedActions() []model.FailedAction {
	var result []model.FailedAction
	if em.store == nil {
		return result
	}
	em.store.LoadAll("DataCache", func(k, v []byte) error {
		var fa model.FailedAction
		if err := json.Unmarshal(v, &fa); err == nil {
			result = append(result, fa)
		}
		return nil
	})
	return result
}

// CRUD Operations

func (em *EdgeComputeManager) UpsertRule(rule model.EdgeRule) error {
	em.mu.Lock()
	defer em.mu.Unlock()

	// Sanitize rule configuration to remove redundant UI data
	em.sanitizeRule(&rule)

	// If update, remove old index entries first
	if _, exists := em.rules[rule.ID]; exists {
		// Note: We need to remove index entries for the OLD rule, not the new one
		// But here we are holding the lock and overwriting.
		// Ideally we should have removed it before.
		// Since we overwrite the map, let's just use removeFromIndex with ruleID
		// But removeFromIndex locks indexMu, so we need to be careful about deadlock if we hold mu.
		// Actually, removeFromIndex uses indexMu, UpsertRule uses mu. Separate locks.
		// BUT we need to call removeFromIndex OUTSIDE of mu if possible or just handle it carefully.
		// However, removeFromIndex iterates ruleIndex.

		// To be safe and clean:
		// 1. We have the old rule in em.rules[rule.ID]
		// 2. We can't call removeFromIndex while holding mu if removeFromIndex might need mu?
		//    No, removeFromIndex only needs indexMu. UpsertRule holds mu.
		//    So it is safe to call removeFromIndex inside UpsertRule.
		em.removeFromIndex(rule.ID)
	}

	em.rules[rule.ID] = rule

	// Add new index
	em.indexRule(rule)

	return em.persist()
}

func (em *EdgeComputeManager) DeleteRule(id string) error {
	em.mu.Lock()
	defer em.mu.Unlock()

	if _, ok := em.rules[id]; !ok {
		return fmt.Errorf("rule not found")
	}

	em.removeFromIndex(id)
	delete(em.rules, id)

	return em.persist()
}

func (em *EdgeComputeManager) GetRules() []model.EdgeRule {
	em.mu.RLock()
	defer em.mu.RUnlock()

	rules := make([]model.EdgeRule, 0, len(em.rules))
	for _, r := range em.rules {
		rules = append(rules, r)
	}
	return rules
}

func (em *EdgeComputeManager) persist() error {
	if em.saveFunc == nil {
		return nil
	}
	rules := make([]model.EdgeRule, 0, len(em.rules))
	for _, r := range em.rules {
		rules = append(rules, r)
	}
	return em.saveFunc(rules)
}

func (em *EdgeComputeManager) restoreState() {
	if em.store == nil {
		return
	}
	// Restore Rule States
	em.store.LoadAll(storage.BucketRuleState, func(k, v []byte) error {
		var state model.RuleRuntimeState
		if err := json.Unmarshal(v, &state); err == nil {
			em.stateMu.Lock()
			em.ruleStates[state.RuleID] = &state
			em.stateMu.Unlock()
		}
		return nil
	})

	// Restore Windows
	em.store.LoadAll(storage.BucketWindow, func(k, v []byte) error {
		var data []model.Value
		if err := json.Unmarshal(v, &data); err == nil {
			em.stateMu.Lock()
			em.windows[string(k)] = data
			em.stateMu.Unlock()
		}
		return nil
	})
	log.Println("Edge Compute state restored from DB")
}

func (em *EdgeComputeManager) saveRuleState(ruleID string) {
	if em.store == nil {
		return
	}
	em.stateMu.RLock()
	statePtr, ok := em.ruleStates[ruleID]
	var stateCopy model.RuleRuntimeState
	if ok && statePtr != nil {
		stateCopy = *statePtr // Shallow copy to avoid race during marshal
	}
	em.stateMu.RUnlock()

	if ok && statePtr != nil {
		if err := em.store.SaveData(storage.BucketRuleState, ruleID, stateCopy); err != nil {
			log.Printf("Failed to save rule state for %s: %v", ruleID, err)
		}
	}
}

func (em *EdgeComputeManager) saveWindowData(ruleID string) {
	if em.store == nil {
		return
	}
	em.stateMu.RLock()
	data, ok := em.windows[ruleID]
	em.stateMu.RUnlock()

	if ok {
		em.store.SaveData(storage.BucketWindow, ruleID, data)
	}
}

func (em *EdgeComputeManager) sanitizeRule(rule *model.EdgeRule) {
	for i := range rule.Actions {
		if rule.Actions[i].Type == "device_control" {
			if targets, ok := rule.Actions[i].Config["targets"].([]interface{}); ok {
				for _, t := range targets {
					if targetMap, ok := t.(map[string]interface{}); ok {
						delete(targetMap, "_deviceList")
						delete(targetMap, "_pointList")
					} else if targetMap, ok := t.(map[string]any); ok {
						delete(targetMap, "_deviceList")
						delete(targetMap, "_pointList")
					}
				}
			}
		}
	}
}
